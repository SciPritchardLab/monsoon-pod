{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea55fc7-4547-4616-b7d1-f63270d7899b",
   "metadata": {},
   "source": [
    "# Download and Save Cloud Data\n",
    "\n",
    "This notebook preprocesses and downloads variables needed to calculate the precipitation-buyancy POD from two cloud stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556d96a-6654-4913-a525-af2ae8ca9cbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f38b2be-cb9b-4c5e-9472-e8ab73faa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import fsspec\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import planetary_computer\n",
    "from datetime import datetime\n",
    "import pystac_client as pystac\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7e48d-6996-4a95-b182-aa23f6aa8b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## User-Defined Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d061ab1-c52c-4ea7-8aee-f4ffffc0042e",
   "metadata": {},
   "source": [
    "Fields defining user information, save directory, and subsetting paramaters (years, months, latitude/longitude/pressure level ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871799ff-87fe-41d5-ba9d-93b6b9a5b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR    = 'Savannah L. Ferretti'\n",
    "EMAIL     = 'savannah.ferretti@uci.edu'\n",
    "SAVEDIR   = '/ocean/projects/atm200007p/sferrett/Repos/monsoon-pr/data/raw'\n",
    "YEARS     = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "MONTHS    = [6,7,8]\n",
    "LATRANGE  = (5.,25.) \n",
    "LONRANGE  = (60.,90.)\n",
    "LEVRANGE  = (500.,1000.)\n",
    "FREQUENCY = 'H'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bbaad-f4d0-46ec-8cb0-a6e0ac4717d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import ERA5 and IMERG Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d2807-fe30-43d4-ba92-cc9f85b5b8ed",
   "metadata": {},
   "source": [
    "Hourly ERA5 data is available via the [LEAP Pangeo Data Catalog](https://catalog.leap.columbia.edu/) at 0.25$^\\circ$ x 0.25$^\\circ$ resolution. Half-hourly IMERG V06 data is available on [Planetary Computer](https://planetarycomputer.microsoft.com/dataset/gpm-imerg) at 0.1$^\\circ$ x 0.1$^\\circ$ resolution. The ```get_era5()``` and ```get_imerg()``` functions lazily load both datasets as Xarray.Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a460b85c-348e-4619-a98e-a546808f3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_era5():\n",
    "    url = 'gs://gcp-public-data-arco-era5/ar/1959-2022-full_37-1h-0p25deg-chunk-1.zarr-v2/'\n",
    "    ds  = xr.open_zarr(url,decode_times=True)\n",
    "    ds  = ds.rename({'latitude':'lat','longitude':'lon','level':'lev'})    \n",
    "    return ds\n",
    "\n",
    "def get_imerg():\n",
    "    url = 'https://planetarycomputer.microsoft.com/api/stac/v1'\n",
    "    catalog = pystac.Client.open(url,modifier=planetary_computer.sign_inplace)\n",
    "    assets  = catalog.get_collection('gpm-imerg-hhr').assets['zarr-abfs']\n",
    "    ds      = xr.open_zarr(fsspec.get_mapper(assets.href,**assets.extra_fields['xarray:storage_options']),consolidated=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adfcfd5-f524-4691-b06c-3e3dca74547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5  = get_era5()\n",
    "imerg = get_imerg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0deb8-eb3a-441f-b19b-742ed7a070f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Specify Variables We Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca7bab-0969-4ec2-83a1-9e35fa3d3eb2",
   "metadata": {},
   "source": [
    "Only four variables are needed from these two datasets: precipitation from IMERG V06, and surface pressure, specific humidity, and temperature from ERA5. Convert units as necessary, and remove unrealistic values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daea4306-137e-4d43-b6ea-1860e89ed29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prdata = (imerg.precipitationCal).where(imerg.precipitationCal>=0,0)*24 #mm/hr to mm/day\n",
    "psdata = era5.surface_pressure/100 # Pa to hPa\n",
    "qdata  = era5.specific_humidity\n",
    "tdata  = era5.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39e91f-1e7d-442a-b1c3-8987f47aec8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c691b2-5e66-45d7-b689-a6343c30bb8c",
   "metadata": {},
   "source": [
    "The ```preprocess()``` function preprocesses each variable using the user-defined fields above. It standardizes dimensions, subsets the time and space dimensions, specifies pressure levels to keep (if applicable), resamples the data to a specified sampling frequency (which can be instantaneous or a time-mean), and regrids the IMERG V06 precipitation data to the same grid as ERA5. It also timestamps the date which these datasets were created, along with the personal information of the user who created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1437672-04ae-4916-aade-7e53433a2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(da):\n",
    "    dims = ['lev','time','lat','lon'] if 'lev' in da.dims else ['time','lat','lon']\n",
    "    for dim in dims:\n",
    "        if dim == 'time' and da.coords[dim].dtype.kind != 'M':\n",
    "            da.coords[dim] = da.indexes[dim].to_datetimeindex()\n",
    "        elif dim != 'time':\n",
    "            da.coords[dim] = da.coords[dim].astype(float)\n",
    "    da = da.sortby(dims).transpose(*dims)\n",
    "    return da\n",
    "\n",
    "def subset(da,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE):\n",
    "    da = da.sel(time=(da['time.year'].isin(years))&(da['time.month'].isin(months)))\n",
    "    da = da.sel(lat=slice(*latrange),lon=slice(*lonrange))\n",
    "    if 'lev' in da.dims:\n",
    "        da = da.sel(lev=slice(*levrange))\n",
    "    return da\n",
    "    \n",
    "def resample(da,frequency=FREQUENCY):\n",
    "    da.coords['time'] = da.time.dt.floor(frequency) \n",
    "    return da.groupby('time').first()\n",
    "\n",
    "def regrid(da,resolution,latrange=LATRANGE,lonrange=LONRANGE):\n",
    "    newlats = np.arange(latrange[0],latrange[1]+resolution,resolution)\n",
    "    newlons = np.arange(lonrange[0],lonrange[1]+resolution,resolution)\n",
    "    da = da.interp(lat=newlats,lon=newlons,kwargs={'fill_value':'extrapolate'})\n",
    "    return da\n",
    "\n",
    "def dataset(da,shortname,longname,units,source,frequency=FREQUENCY,author=AUTHOR,email=EMAIL):\n",
    "    vardata = {shortname:([*da.dims],da.data)}\n",
    "    coords  = {dim:da.coords[dim].data for dim in da.dims}\n",
    "    ds = xr.Dataset(vardata,coords)\n",
    "    ds[shortname].attrs = dict(long_name=longname,units=units)\n",
    "    ds.time.attrs = dict(long_name='Time')\n",
    "    ds.lat.attrs  = dict(long_name='Latitude',units='°N')\n",
    "    ds.lon.attrs  = dict(long_name='Longitude',units='°E')\n",
    "    if 'lev' in ds.dims:\n",
    "        ds.lev.attrs = dict(long_name='Pressure level',units='hPa')\n",
    "    ds.attrs = dict(source=source,history=f'Created on {datetime.today().strftime(\"%Y-%m-%d\")} by {author} ({email})')\n",
    "    return ds\n",
    "\n",
    "def preprocess(da,shortname,longname,units,source,years=YEARS,months=MONTHS,resolution=None,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE,frequency=FREQUENCY,author=AUTHOR,email=EMAIL):\n",
    "    da = standardize(da)\n",
    "    da = subset(da,years,months,latrange,lonrange,levrange)\n",
    "    if xr.infer_freq(da.time) != frequency:\n",
    "        da = resample(da,frequency)\n",
    "    if resolution:\n",
    "        da = regrid(da,resolution)\n",
    "    ds = dataset(da,shortname,longname,units,source,author,email)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580f3eea-928f-4884-905f-919e76ca2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = preprocess(prdata,resolution=0.25,shortname='pr',longname='Precipitation flux',units='mm/day',source='IMERG V06')\n",
    "ps = preprocess(psdata,shortname='ps',longname='Surface pressure',units='hPa',source='ERA5')\n",
    "q  = preprocess(qdata,shortname='q',longname='Specific humidity',units='kg/kg',source='ERA5')\n",
    "t  = preprocess(tdata,shortname='t',longname='Air temperature',units='K',source='ERA5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eea6ca7-1f27-400a-92fb-a72e8466833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of pr: 1.82 GB\n",
      "Size of ps: 1.82 GB\n",
      "Size of q:  29.09 GB\n",
      "Size of t:  29.09 GB\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of pr: {pr.nbytes*1e-9:.2f} GB')\n",
    "print(f'Size of ps: {ps.nbytes*1e-9:.2f} GB')\n",
    "print(f'Size of q:  {q.nbytes*1e-9:.2f} GB')\n",
    "print(f'Size of t:  {t.nbytes*1e-9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb9ec1-b257-40f4-a368-a28a15dd583a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7031bd7-f13d-405e-b88f-7a640ffa7235",
   "metadata": {},
   "source": [
    "Save each variable Xarray.Dataset as a netCDF file to the user-defined save directory (```SAVEDIR```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca45f0d1-bb43-48e4-acb1-858f0300e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ds,filename,savedir=SAVEDIR):\n",
    "    filepath = f'{savedir}/{filename}'\n",
    "    ds.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d135dd-bd36-4c1a-8858-b9bb7cba43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pr,'IMERG_precipitation_flux.nc') # 22min 24s\n",
    "save(ps,'ERA5_surface_pressure.nc')    # 7min 3s\n",
    "save(q,'ERA5_specific_humidity.nc')    #   \n",
    "save(t,'ERA5_temperature.nc')          # 3h 32min 51s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f8be3-568e-4cf6-8068-76ed5d49b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save(q,'ERA5_specific_humidity.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-pr",
   "language": "python",
   "name": "monsoon-pr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
