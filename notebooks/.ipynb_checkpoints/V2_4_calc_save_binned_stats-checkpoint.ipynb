{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d067b0a9-924e-4624-90a2-46ffef7deeca",
   "metadata": {},
   "source": [
    "# Aggregate Regional and Monthly Statistics\n",
    "\n",
    "This notebook aggregates 1D and 2D binned statistics needed for figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226886d6-cdbe-415e-898e-f66abb69d406",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba6191d-0e3a-4d06-9b20-b2cf5967515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94938f29-9b96-4c40-bb8b-aeaf73ccba81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## User-Defined Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55d701-041e-441e-a114-6c27d272ad5d",
   "metadata": {},
   "source": [
    "Define the user's name/email, specify the directory where the P-$B_L$ data is, and set the directory where the binned statistics will be saved. Define subregions of interest with their respective latitude/longitude bounds, and set binning parameters for $B_L$/$\\mathrm{CAPE_L}$/$\\mathrm{SUBSAT_L}$, along with the precipitation threhsold (in mm/day) separating precipitating from non-precipitating regimes (in mm/day). Specify the months for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd25cf9-38d2-46d6-954b-c5a4f6af9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR    = 'Savannah L. Ferretti'\n",
    "EMAIL     = 'savannah.ferretti@uci.edu'\n",
    "FILEDIR   = '/global/cfs/cdirs/m4334/sferrett/monsoon-pod/data/processed'\n",
    "SAVEDIR   = '/global/cfs/cdirs/m4334/sferrett/monsoon-pod/data/processed'\n",
    "REGIONS   = {\n",
    "    'Eastern Arabian Sea':{'latmin':9.,'latmax':19.5,'lonmin':64.,'lonmax':72.}, \n",
    "    'Central India':{'latmin':18.,'latmax':24.,'lonmin':76.,'lonmax':83.},\n",
    "    'Central Bay of Bengal':{'latmin':9.,'latmax':14.5,'lonmin':86.5,'lonmax':90.},\n",
    "    'Equatorial Indian Ocean':{'latmin':5.,'latmax':10.,'lonmin':62.,'lonmax':67.5},\n",
    "    'Konkan Coast':{'latmin':15.,'latmax':19.5,'lonmin':69.,'lonmax':72.5}} \n",
    "BINPARAMS = {\n",
    "    'bl':{'min':-0.6,'max':0.1,'width':0.0025},\n",
    "    'cape':{'min':-70.,'max':20.,'width':1.},\n",
    "    'subsat':{'min':-20.,'max':70.,'width':1.}}\n",
    "PRTHRESH  = 0.25\n",
    "MONTHS    = [6,7,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb26ec-9516-4c04-a897-7aafcecd41ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load $P$-$B_L$ Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00426ff-ed3d-40e0-b377-10ef9904024d",
   "metadata": {},
   "source": [
    "Load in the high- and low-resolution P-$B_L$ datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25380384-32cd-4692-a567-20b3bf859307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename,filedir=FILEDIR):\n",
    "    filepath = f'{filedir}/{filename}'\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    return ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80200483-2b09-4594-b919-9c0cec66b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "hirespbl = load('ERA5_IMERG_pr_bl_terms.nc')\n",
    "lorespbl = load('ERA5_GPCP_pr_bl_terms.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d43bf-fbef-4813-9665-0aca319985ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions for Calculating Binned Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbfc23-c40d-4aed-bbd8-afe8a13bc780",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Subset Region and Month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181598cd-79d2-4d35-9a94-b71ab1588e80",
   "metadata": {},
   "source": [
    "Subset the loaded dataset by the region of interest, and subset temporally for data within a specific month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7503959-3a72-443b-8c8f-127883c2160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(data,key,regions=REGIONS):\n",
    "    region = regions[key]\n",
    "    return data.sel(lat=slice(region['latmin'],region['latmax']),lon=slice(region['lonmin'],region['lonmax']))\n",
    "\n",
    "def get_month(data,month):\n",
    "    return data.sel(time=data.time.dt.month==month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880d067-ec82-4e3e-8288-1d87b11f6136",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculate Binned Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba22c7-8c08-463d-8131-55e2c24c991c",
   "metadata": {},
   "source": [
    "Establish 1D ($B_L$) and 2D (joint $\\text{SUBSAT}_\\text{L}$-$\\text{CAPE}_\\text{L}$) bins for which to aggregate statistics: count of precipitating data points, sum of precipitation values, and  sum of squared precipitation values in each 1D and 2D bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18641021-7114-4fd8-9b10-6694d3165f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_edges(key,binparams=BINPARAMS):\n",
    "    varname  = binparams[key]\n",
    "    binedges = np.arange(varname['min'],varname['max']+varname['width'],varname['width'])\n",
    "    return binedges\n",
    "\n",
    "def calc_binned_stats(data,binparams=BINPARAMS,prthresh=PRTHRESH,author=AUTHOR,email=EMAIL):\n",
    "    blbins      = get_bin_edges('bl')\n",
    "    capebins    = get_bin_edges('cape')\n",
    "    subsatbins  = get_bin_edges('subsat')\n",
    "    blidxs      = ((data.bl.values-binparams['bl']['min'])/binparams['bl']['width']+0.5).astype(int)\n",
    "    capeidxs    = ((data.cape.values-binparams['cape']['min'])/binparams['cape']['width']-0.5).astype(int)\n",
    "    subsatidxs  = ((data.subsat.values-binparams['subsat']['min'])/binparams['subsat']['width']-0.5).astype(int)\n",
    "    nblbins     = blbins.size\n",
    "    ncapebins   = capebins.size\n",
    "    nsubsatbins = subsatbins.size\n",
    "    Q0 = np.zeros((nblbins))\n",
    "    Q1 = np.zeros((nblbins))\n",
    "    Q2 = np.zeros((nblbins))\n",
    "    QE = np.zeros((nblbins))\n",
    "    P0 = np.zeros((nsubsatbins,ncapebins))\n",
    "    P1 = np.zeros((nsubsatbins,ncapebins))\n",
    "    P2 = np.zeros((nsubsatbins,ncapebins))\n",
    "    PE = np.zeros((nsubsatbins,ncapebins))\n",
    "    for timeidx in range(len(data.time)):\n",
    "        for latidx in range(len(data.lat)):\n",
    "            for lonidx in range(len(data.lon)):\n",
    "                prval       = data.pr.values[timeidx,latidx,lonidx]\n",
    "                blidx       = blidxs[timeidx,latidx,lonidx]\n",
    "                capeidx     = capeidxs[timeidx,latidx,lonidx]\n",
    "                subsatidx   = subsatidxs[timeidx,latidx,lonidx]\n",
    "                validpr     = np.isfinite(prval)\n",
    "                validbl     = (0<=blidx<nblbins)\n",
    "                validcape   = (0<=capeidx<ncapebins)\n",
    "                validsubsat = (0<=subsatidx<nsubsatbins)\n",
    "                if validbl & validpr:\n",
    "                    Q0[blidx] += 1 \n",
    "                    Q1[blidx] += prval\n",
    "                    Q2[blidx] += prval**2\n",
    "                    if prval > prthresh:\n",
    "                        QE[blidx] += 1\n",
    "                if validcape & validsubsat & validpr:\n",
    "                    P0[subsatidx,capeidx] += 1\n",
    "                    P1[subsatidx,capeidx] += prval\n",
    "                    P2[subsatidx,capeidx] += prval**2\n",
    "                    if prval > prthresh:\n",
    "                        PE[subsatidx,capeidx] += 1\n",
    "    ds = xr.Dataset(data_vars={'Q0':(('bl'),Q0),'QE':(('bl'),QE),'Q1':(('bl'),Q1),'Q2':(('bl'),Q2),\n",
    "                               'P0':(('subsat','cape'),P0),'PE':(('subsat','cape'),PE),\n",
    "                               'P1':(('subsat','cape'),P1),'P2':(('subsat','cape'),P2)},\n",
    "                          coords={'subsat':subsatbins,'cape':capebins,'bl':blbins})\n",
    "    ds.Q0.attrs     = dict(long_name='Count of points in each bin')\n",
    "    ds.QE.attrs     = dict(long_name=f'Count of precipitating ( > {prthresh} mm/day) points in each bin')\n",
    "    ds.Q1.attrs     = dict(long_name='Sum of precipitation in each bin',units='mm/day')\n",
    "    ds.Q2.attrs     = dict(long_name='Sum of squared precipitation in each bin',units='mm²/day²')\n",
    "    ds.P0.attrs     = dict(long_name='Count of points in each bin')\n",
    "    ds.PE.attrs     = dict(long_name=f'Count of precipitating ( > {prthresh} mm/day) points in each bin')\n",
    "    ds.P1.attrs     = dict(long_name='Sum of precipitation in each bin',units='mm/day')\n",
    "    ds.P2.attrs     = dict(long_name='Sum of squared precipitation in each bin',units='mm²/day²')\n",
    "    ds.cape.attrs   = dict(long_name='Undilute plume buoyancy',units='K')\n",
    "    ds.subsat.attrs = dict(long_name='Subsaturation in the lower free-troposphere',units='K')\n",
    "    ds.bl.attrs     = dict(long_name='Average buoyancy in the lower troposphere',units='m/s²')\n",
    "    ds.attrs        = dict(history=f'Created on {datetime.today().strftime(\"%Y-%m-%d\")} by {author} ({email})')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e0096-a94b-4bcf-87d8-2bc42c086aad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Execute Binned Statistics Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c700d-8b26-4334-9279-4b87d99623bf",
   "metadata": {},
   "source": [
    "Since the analysis is quite compute-intensive (for the high-resolution data), we execute the aforementioned workflow by subregion. ```process_by_subregion()``` creates monthy binned statistics, datasets, aggregates them by subregion, and merges them into a single Xarray.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff0af06-521b-4026-a5d1-a98f1656f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_by_subregion(ds,months=MONTHS,regions=REGIONS):\n",
    "    regionstatslist = []\n",
    "    for region in regions:\n",
    "        regiondata     = get_region(ds,region)\n",
    "        monthstatslist = []\n",
    "        for month in months:\n",
    "            monthdata  = get_month(regiondata,month)\n",
    "            monthstats = calc_binned_stats(monthdata)\n",
    "            monthstatslist.append(monthstats.expand_dims({'month':[month]}))\n",
    "        regionstats = xr.concat(monthstatslist,dim='month')\n",
    "        regionstatslist.append(regionstats.expand_dims({'region':[region]}))\n",
    "    return xr.concat(regionstatslist,dim='region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8708258-ef32-4787-9ff7-1035ce977cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiresstats = process_by_subregion(hirespbl)\n",
    "loresstats = process_by_subregion(lorespbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f914fa-69eb-4aed-9ac1-90fd80ab8188",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Statistics Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3606d20-20cf-422e-a22b-81fcf661be4b",
   "metadata": {},
   "source": [
    "Put all regions into a singular Xarray.Dataset, and save as a netCDF file to the user-defined save directory (```SAVEDIR```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3761f6f8-7d1d-4daa-9ac8-68ef204946b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ds,filename,savedir=SAVEDIR):\n",
    "    filepath = f'{savedir}/{filename}'\n",
    "    ds.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8097609f-f081-49ec-a886-88cd4b666171",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(hiresstats,'ERA5_IMERG_binned_stats.nc')\n",
    "save(loresstats,'ERA5_GPCP_binned_stats.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-pod",
   "language": "python",
   "name": "monsoon-pod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
