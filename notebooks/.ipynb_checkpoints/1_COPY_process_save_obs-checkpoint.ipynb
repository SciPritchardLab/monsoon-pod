{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea55fc7-4547-4616-b7d1-f63270d7899b",
   "metadata": {},
   "source": [
    "# Download and Save Cloud Data\n",
    "\n",
    "This notebook downloads variables needed to calculate the precipitation-buoyancy POD from multiple cloud stores. The following code obtains and preprocesses thermodynamic variables from ERA5, and precipitation from both IMERG V06 and GPCP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556d96a-6654-4913-a525-af2ae8ca9cbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f38b2be-cb9b-4c5e-9472-e8ab73faa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf\n",
    "import gcsfs\n",
    "import fsspec\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import planetary_computer\n",
    "from datetime import datetime\n",
    "import pystac_client as pystac\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7e48d-6996-4a95-b182-aa23f6aa8b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## User-Defined Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d061ab1-c52c-4ea7-8aee-f4ffffc0042e",
   "metadata": {},
   "source": [
    "Define user information (for data download attribution), the directory where the data should be saved to, and subsetting parameters (years, months, latitude/longitude/pressure level ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871799ff-87fe-41d5-ba9d-93b6b9a5b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR    = 'Savannah L. Ferretti'      \n",
    "EMAIL     = 'savannah.ferretti@uci.edu' \n",
    "SAVEDIR   = '/ocean/projects/atm200007p/sferrett/Repos/monsoon-pr/data/raw'\n",
    "YEARS     = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "MONTHS    = [6,7,8]\n",
    "LATRANGE  = (5.,25.) \n",
    "LONRANGE  = (60.,90.)\n",
    "LEVRANGE  = (500.,1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bbaad-f4d0-46ec-8cb0-a6e0ac4717d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import and Preproccess Cloud Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d2807-fe30-43d4-ba92-cc9f85b5b8ed",
   "metadata": {},
   "source": [
    "The raw data for this analysis is accessible through publicly available cloud stores. ERA5 data, at its native hourly frequency and 0.25° x 0.25° spatial resolution, can be found on the LEAP Pangeo Data Catalog [here](https://catalog.leap.columbia.edu/feedstock/arco-era5). IMERG V06 data, provided at half-hourly frequency at 0.1° x 0.1° spatial resolution, can be accessed via Microsoft Planetary Computer [here](https://planetarycomputer.microsoft.com/dataset/gpm-imerg). GPCP data, available at daily frequency with 1.0° x 1.0° spatial resolution, is also hosted on the LEAP Pangeo Data Catalog [here](https://catalog.leap.columbia.edu/feedstock/global-precipitation-climatology-project). To efficiently handle these large datasets, the following functions lazily load all data using Xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a460b85c-348e-4619-a98e-a546808f3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_era5():\n",
    "    store = 'gs://gcp-public-data-arco-era5/ar/1959-2022-full_37-1h-0p25deg-chunk-1.zarr-v2/'\n",
    "    ds    = xr.open_zarr(store,decode_times=True)  \n",
    "    return ds\n",
    "\n",
    "def get_imerg():\n",
    "    store   = 'https://planetarycomputer.microsoft.com/api/stac/v1'\n",
    "    catalog = pystac.Client.open(store,modifier=planetary_computer.sign_inplace)\n",
    "    assets  = catalog.get_collection('gpm-imerg-hhr').assets['zarr-abfs']\n",
    "    ds      = xr.open_zarr(fsspec.get_mapper(assets.href,**assets.extra_fields['xarray:storage_options']),consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def get_gpcp():\n",
    "    store = 'https://ncsa.osn.xsede.org/Pangeo/pangeo-forge/gpcp-feedstock/gpcp.zarr'\n",
    "    ds    = xr.open_dataset(store,engine='zarr',chunks={})   \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1adfcfd5-f524-4691-b06c-3e3dca74547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5data  = get_era5()\n",
    "imergdata = get_imerg()\n",
    "gpcpdata  = get_gpcp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600f1c5-01e5-4319-a8bb-f72da8fa667b",
   "metadata": {},
   "source": [
    "The ```preprocess()``` function preprocesses each variable using the user-defined fields specified above. It executes two functions: one that standardizes dimensions across datasets, and another that subsets the time and space dimensions and specifies pressure levels to keep (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60071fa-6aa5-47f9-98b8-ad602dab0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(ds):\n",
    "    dimnames = {'latitude':'lat','longitude':'lon','level':'lev'}\n",
    "    ds = ds.rename({oldname:newname for oldname,newname in dimnames.items() if oldname in ds.dims})\n",
    "    targetdims = ['lev','time','lat','lon'] if 'lev' in ds.dims else ['time','lat','lon']\n",
    "    extradims  = [dim for dim in ds.dims if dim not in targetdims]\n",
    "    if extradims:\n",
    "        ds = ds.drop_dims(extradims)\n",
    "    for dim in targetdims:\n",
    "        if dim=='time' and ds.coords[dim].dtype.kind!='M':\n",
    "            ds.coords[dim] = ds.indexes[dim].to_datetimeindex()\n",
    "            ds = ds.sel(time=~ds.time.to_index().duplicated(keep='first'))\n",
    "        elif dim=='lon':\n",
    "            ds.coords[dim] = (ds.coords[dim]+180)%360-180        \n",
    "        elif dim!='time':\n",
    "            ds.coords[dim] = ds.coords[dim].astype(float)\n",
    "    ds = ds.sortby(targetdims).transpose(*targetdims)   \n",
    "    return ds\n",
    "\n",
    "def subset(da,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE):\n",
    "    da = da.sel(time=(da['time.year'].isin(years))&(da['time.month'].isin(months)))\n",
    "    da = da.sel(lat=slice(*latrange),lon=slice(*lonrange))\n",
    "    if 'lev' in da.dims:\n",
    "        da = da.sel(lev=slice(*levrange))\n",
    "    return da\n",
    "\n",
    "def preprocess(da,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE):\n",
    "    da = standardize(da)\n",
    "    da = subset(da,years,months,latrange,lonrange,levrange)\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca65b2e-90c2-49b2-a37b-bd537a413c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp  = preprocess(gpcpdata)\n",
    "imerg = preprocess(imergdata)\n",
    "era5  = preprocess(era5data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad1ff5c-9e27-4ab4-970a-d103980780de",
   "metadata": {},
   "source": [
    "## Extract Necessary Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca7bab-0969-4ec2-83a1-9e35fa3d3eb2",
   "metadata": {},
   "source": [
    "Only four variables are needed from across these three datasets: precipitation (in mm/day) from IMERG V06 and GPCP, and surface pressure (hPa), specific humidity (kg/kg), and temperature (K) from ERA5. Convert units as necessary, and remove unrealistic values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daea4306-137e-4d43-b6ea-1860e89ed29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcpdata  = gpcp.precip.where(gpcp.precip>=0,0)\n",
    "imergdata = (imerg.precipitationCal).where(imerg.precipitationCal>=0,0)*24 # From mm/hr to mm/day\n",
    "psdata    = era5.surface_pressure/100 # From Pa to hPa\n",
    "qdata     = era5.specific_humidity\n",
    "tdata     = era5.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17eea5-5295-42d0-a335-4bab94b28f6b",
   "metadata": {},
   "source": [
    "## Create Observational Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5748135-3186-48c1-9360-f15b0c295d89",
   "metadata": {},
   "source": [
    "Our three datasets have different temporal frequencies and spatial resolution. Therefore, regridding and resampling of the data is needed to make temporally and spatially-consistent datasets ready for analysis. ```regrid()``` uses [xESMF](https://xesmf.readthedocs.io/en/stable/) to convert between rectilinear grids, and ```resample()``` changes the sampling frequency/takes temporal means (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd2e897-5c9b-404d-b615-7a3542ed4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid(da,gridsource,gridtarget):\n",
    "    regridder = xesmf.Regridder(gridsource,gridtarget,method='bilinear',keep_attrs=True)\n",
    "    return regridder(da)\n",
    "\n",
    "def resample(da,frequency,method):\n",
    "    if frequency not in ['H','D']:\n",
    "        raise ValueError(\"Frequency must be 'H' (hourly) or 'D' (daily)\")\n",
    "    if method=='mean':\n",
    "        return da.resample(time=frequency).mean()\n",
    "    elif method=='first':\n",
    "        return da.resample(time=frequency).first()\n",
    "    elif method=='last':\n",
    "        return da.resample(time=frequency).last()\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'mean', 'first', or 'last'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39e91f-1e7d-442a-b1c3-8987f47aec8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c691b2-5e66-45d7-b689-a6343c30bb8c",
   "metadata": {},
   "source": [
    "The ```preprocess()``` function preprocesses each variable using the user-defined fields above. It standardizes dimensions, subsets the time and space dimensions, specifies pressure levels to keep (if applicable), resamples the data to a specified sampling frequency (which can be instantaneous or a time-mean), and regrids the IMERG V06 precipitation data to the same grid as ERA5. It also timestamps the date which these datasets were created, along with the personal information of the user who created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1437672-04ae-4916-aade-7e53433a2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(da):\n",
    "    dimnames = {'latitude':'lat','longitude':'lon','level':'lev'}\n",
    "    da = da.rename({oldname:newname for oldname,newname in dimnames.items() if oldname in da.dims})\n",
    "    dims = ['lev','time','lat','lon'] if 'lev' in da.dims else ['time','lat','lon']\n",
    "    for dim in dims:\n",
    "        if dim == 'time' and da.coords[dim].dtype.kind != 'M':\n",
    "            da.coords[dim] = da.indexes[dim].to_datetimeindex()\n",
    "        elif dim != 'time':\n",
    "            da.coords[dim] = da.coords[dim].astype(float)\n",
    "    da = da.sortby(dims).transpose(*dims)\n",
    "    return da\n",
    "\n",
    "def subset(da,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE):\n",
    "    da = da.sel(time=(da['time.year'].isin(years))&(da['time.month'].isin(months)))\n",
    "    da = da.sel(lat=slice(*latrange),lon=slice(*lonrange))\n",
    "    if 'lev' in da.dims:\n",
    "        da = da.sel(lev=slice(*levrange))\n",
    "    return da\n",
    "    \n",
    "def resample(da,frequency=FREQUENCY):\n",
    "    da.coords['time'] = da.time.dt.floor(frequency) \n",
    "    return da.groupby('time').first()\n",
    "\n",
    "def regrid(da,resolution,latrange=LATRANGE,lonrange=LONRANGE):\n",
    "    newlats = np.arange(latrange[0],latrange[1]+resolution,resolution)\n",
    "    newlons = np.arange(lonrange[0],lonrange[1]+resolution,resolution)\n",
    "    da = da.interp(lat=newlats,lon=newlons,kwargs={'fill_value':'extrapolate'})\n",
    "    return da\n",
    "\n",
    "def preprocess(da,shortname,longname,units,source,years=YEARS,months=MONTHS,resolution=None,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE,frequency=FREQUENCY,author=AUTHOR,email=EMAIL):\n",
    "    da = standardize(da)\n",
    "    da = subset(da,years,months,latrange,lonrange,levrange)\n",
    "    if xr.infer_freq(da.time) != frequency:\n",
    "        da = resample(da,frequency)\n",
    "    if resolution:\n",
    "        da = regrid(da,resolution)\n",
    "    ds = xr.Dataset(data_vars={shortname:([*da.dims],da.data)},\n",
    "                    coords={dim:da.coords[dim].data for dim in da.dims})\n",
    "    ds[shortname].attrs = dict(long_name=longname,units=units)\n",
    "    ds.time.attrs = dict(long_name='Time')\n",
    "    ds.lat.attrs  = dict(long_name='Latitude',units='°N')\n",
    "    ds.lon.attrs  = dict(long_name='Longitude',units='°E')\n",
    "    if 'lev' in ds.dims:\n",
    "        ds.lev.attrs = dict(long_name='Pressure level',units='hPa')\n",
    "    ds.attrs = dict(source=source,history=f'Created on {datetime.today().strftime(\"%Y-%m-%d\")} by {author} ({email})')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580f3eea-928f-4884-905f-919e76ca2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = preprocess(prdata,resolution=0.25,shortname='pr',longname='Precipitation flux',units='mm/day',source='IMERG V06')\n",
    "ps = preprocess(psdata,shortname='ps',longname='Surface pressure',units='hPa',source='ERA5')\n",
    "q  = preprocess(qdata,shortname='q',longname='Specific humidity',units='kg/kg',source='ERA5')\n",
    "t  = preprocess(tdata,shortname='t',longname='Air temperature',units='K',source='ERA5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eea6ca7-1f27-400a-92fb-a72e8466833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of pr: 1.82 GB\n",
      "Size of ps: 1.82 GB\n",
      "Size of q:  29.09 GB\n",
      "Size of t:  29.09 GB\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of pr: {pr.nbytes*1e-9:.2f} GB')\n",
    "print(f'Size of ps: {ps.nbytes*1e-9:.2f} GB')\n",
    "print(f'Size of q:  {q.nbytes*1e-9:.2f} GB')\n",
    "print(f'Size of t:  {t.nbytes*1e-9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb9ec1-b257-40f4-a368-a28a15dd583a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7031bd7-f13d-405e-b88f-7a640ffa7235",
   "metadata": {},
   "source": [
    "Save each variable Xarray.Dataset as a netCDF file to the user-defined save directory (```SAVEDIR```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca45f0d1-bb43-48e4-acb1-858f0300e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ds,filename,savedir=SAVEDIR):\n",
    "    filepath = f'{savedir}/{filename}'\n",
    "    ds.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82d135dd-bd36-4c1a-8858-b9bb7cba43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pr,'IMERG_precipitation_flux.nc') # 22m 24s\n",
    "save(ps,'ERA5_surface_pressure.nc')    # 7m 3s\n",
    "save(q,'ERA5_specific_humidity.nc')    # 4h 2m 11s\n",
    "save(t,'ERA5_temperature.nc')          # 3h 32m 51s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-pod",
   "language": "python",
   "name": "monsoon-pod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
